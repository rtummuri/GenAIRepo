{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d693f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "A PromptTemplate:\n",
    "Is a reusable template for generating prompts.\n",
    "Includes placeholders (input_variables) that can be replaced with dynamic content at runtime.\n",
    "Simplifies the process of customizing prompts for different inputs while maintaining consistent structure.\n",
    "Key Components\n",
    "input_variables: \n",
    "    A list of variable names that will be dynamically replaced. \n",
    "    These placeholders allow you to adapt the template for various inputs.\n",
    "template: \n",
    "    A string containing the static part of the prompt and placeholders for the dynamic parts.\n",
    "    The placeholders are written as {variable_name}.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f7cebb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import API Keys\n",
    "%run ../../../conf/apikey.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ea098f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ddae11d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a helpful assistant. Answer the following question about LangChain: What are Prompt Templates?\n",
      "{'topic': 'LangChain', 'question': 'What are Prompt Templates?', 'text': 'Prompt Templates in LangChain are preset messages or scripts that can be used to quickly respond to customer inquiries or provide standardized information. These templates help streamline communication and ensure consistency in responses across the platform. Users can also customize and create their own prompt templates to better address their specific needs.'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Declare basic prompt with dynamic input\n",
    "prompt = PromptTemplate(\n",
    "input_variables = [\"topic\",\"question\"],\n",
    "template = \"You are a helpful assistant. Answer the following question about {topic}: {question}\")\n",
    "\n",
    "promptWithValues = prompt.format(topic=\"LangChain\",question=\"What are Prompt Templates?\")\n",
    "print(promptWithValues)\n",
    "\n",
    "# Create an LLM instance\n",
    "llm = ChatOpenAI()\n",
    "\n",
    "# Combine LLM and PromptTemplate into a chain\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "# Run the chain with dynamic input\n",
    "response = chain.invoke({\"topic\": \"LangChain\", \"question\": \"What are Prompt Templates?\"})\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d29703b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Context: You are a helpful assistant. Answer the following question about LangChain \n",
      "Question: What are Prompt Templates?\n",
      "Answer: \n",
      "{'topic': 'LangChain', 'question': 'What are Prompt Templates?', 'text': 'Prompt Templates are predefined templates provided by LangChain that guide users on how to structure their writing prompts. These templates help users create more engaging and effective prompts for the LangChain platform.'}\n"
     ]
    }
   ],
   "source": [
    "#Declare contextual prompt with dynamic input\n",
    "prompt = PromptTemplate(\n",
    "input_variables = [\"topic\",\"question\"],\n",
    "template = \"\"\" Context: You are a helpful assistant. Answer the following question about {topic} \n",
    "Question: {question}\n",
    "Answer: \"\"\"\n",
    ")\n",
    "\n",
    "promptWithValues = prompt.format(topic=\"LangChain\",question=\"What are Prompt Templates?\")\n",
    "print(promptWithValues)\n",
    "\n",
    "# Create an LLM instance\n",
    "llm = ChatOpenAI()\n",
    "\n",
    "# Combine LLM and PromptTemplate into a chain\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "# Run the chain with dynamic input\n",
    "response = chain.invoke({\"topic\": \"LangChain\", \"question\": \"What are Prompt Templates?\"})\n",
    "print(response)\n",
    "print(response[\"text\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b76fed16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: Farm animal\n"
     ]
    }
   ],
   "source": [
    "from langchain import  FewShotPromptTemplate\n",
    "\n",
    "#Declare few shot prompt\n",
    "examples = [\n",
    "    { \"question\": \"Dos is\", \n",
    "      \"answer\": \"Pet animal\"},\n",
    "    { \"question\": \"Cat is\", \n",
    "      \"answer\": \"Pet animal\"},\n",
    "    { \"question\": \"Tiger is\", \n",
    "      \"answer\": \"Wild animal\"},\n",
    "    { \"question\": \"Lion is\", \n",
    "      \"answer\": \"Wild animal\"}\n",
    "]\n",
    "prompt = PromptTemplate(\n",
    "input_variables = [\"question\",\"answer\"],\n",
    "template = \"\"\"\n",
    "Question: {question}\n",
    "Answer: {answer} \"\"\"\n",
    ")\n",
    "#Inject xample questions into PromptTemplate\n",
    "#print(prompt.format(**examples[0]))\n",
    "\n",
    "few_shot_prompt = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=prompt,\n",
    "    #prefix=\"Respond with a funny and witty remark.\",\n",
    "    suffix=\"question: {question}\",\n",
    "    input_variables=[\"question\"]\n",
    "    #example_separator=\"\"\n",
    ")\n",
    "#Inject example questions into FewShotPromptTemplate \n",
    "#print(few_shot_prompt.format(question=\"Cow is\"))\n",
    "\n",
    "llm_chain = LLMChain(prompt=few_shot_prompt, llm=llm)\n",
    "chain_response = llm_chain.run(question=\"Cow is\")\n",
    "print(chain_response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "00af867d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='You are a helpful assistant that translates English to Spanish.', additional_kwargs={}, response_metadata={}), HumanMessage(content=\"I'm hungry, give me food.\", additional_kwargs={}, response_metadata={})]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Tengo hambre, dame comida.'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Chat Prompt Template\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    PromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    AIMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "\n",
    "system_message=\"You are a helpful assistant that translates {input_language} to {output_language}.\"\n",
    "system_message_promt = SystemMessagePromptTemplate.from_template(system_message)\n",
    "\n",
    "human_message=\"{text}\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_message)\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message_promt,human_message_prompt])\n",
    "messages = chat_prompt.format_prompt(input_language=\"English\", output_language=\"Spanish\", \n",
    "                                     text=\"I'm hungry, give me food.\").to_messages()\n",
    "print(messages)\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "response = llm(messages)\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716ae4e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
